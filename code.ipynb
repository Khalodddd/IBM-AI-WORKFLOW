{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_json_files\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# API Endpoints\u001b[39;00m\n\u001b[0;32m     10\u001b[0m TRAIN_API_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8000/train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from model.data_ingestion import load_json_files\n",
    "\n",
    "# API Endpoints\n",
    "TRAIN_API_URL = \"http://localhost:8000/train\"\n",
    "PREDICT_API_URL = \"http://localhost:8000/predict\"\n",
    "\n",
    "# Data Directories\n",
    "TRAIN_DATA_DIR = \"data/cs-train\"\n",
    "PREDICTION_DATA_DIR = \"data/cs-production\"\n",
    "OUTPUT_PREDICTION_FILE = \"predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_model_training():\n",
    "    \"\"\"\n",
    "    Send a request to the API to train the models using the provided training data directory.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"data_dir\": TRAINING_DATA_PATH,\n",
    "        \"test\": True\n",
    "    }\n",
    "    response = requests.post(TRAIN_API_ENDPOINT, json=payload)\n",
    "    \n",
    "    if response.ok:\n",
    "        print(\"Model training completed successfully.\")\n",
    "    else:\n",
    "        print(f\"Model training failed with status code {response.status_code}: {response.text}\")\n",
    "initiate_model_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_data(data_directory):\n",
    "    \"\"\"\n",
    "    Load data from JSON files located in the specified directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_directory (str): The directory containing JSON files.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    return load_json_files(data_directory)\n",
    "\n",
    "\n",
    "prediction_data_frame = load_prediction_data(PREDICTION_DATA_PATH)\n",
    "prediction_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_batch_predictions(data_frame):\n",
    "    \"\"\"\n",
    "    Perform predictions for each record in the provided DataFrame using the prediction API.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_frame (DataFrame): The DataFrame containing data for prediction.\n",
    "    \n",
    "    Returns:\n",
    "    - List[Dict]: A list of dictionaries containing prediction results.\n",
    "    \"\"\"\n",
    "    prediction_results = []\n",
    "    \n",
    "    for _, record in data_frame.iterrows():\n",
    "        payload = {\n",
    "            \"country\": record['country'],\n",
    "            \"year\": record['year'],\n",
    "            \"month\": record['month'],\n",
    "            \"day\": record['day'],\n",
    "            \"test\": True\n",
    "        }\n",
    "        response = requests.post(PREDICT_API_ENDPOINT, json=payload)\n",
    "        \n",
    "        if response.ok:\n",
    "            result = response.json()\n",
    "            result.update({\n",
    "                'invoice_id': record['invoice'],\n",
    "                'country_code': record['country'],\n",
    "                'total_amount': record['total_price'],\n",
    "                'transaction_date': f\"{record['year']}-{record['month']}-{record['day']}\"\n",
    "            })\n",
    "            prediction_results.append(result)\n",
    "        else:\n",
    "            print(f\"Prediction failed for invoice {record['invoice']}: {response.text}\")\n",
    "    \n",
    "    return prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redicted_results = perform_batch_predictions(prediction_data_frame)\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df = pd.DataFrame(predicted_results)\n",
    "predictions_df.to_csv(OUTPUT_PREDICTIONS_FILE, index=False)\n",
    "\n",
    "# Display the first few predictions\n",
    "predictions_df.head()\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "# Aggregate revenue by country\n",
    "country_revenue = predictions_df.groupby('country_code')['total_amount'].sum().reset_index()\n",
    "country_revenue = country_revenue.rename(columns={'total_amount': 'total_revenue'}).sort_values('total_revenue', ascending=False)\n",
    "country_revenue.head()\n",
    "\n",
    "# Basic statistics of the predictions\n",
    "predictions_df.describe()\n",
    "\n",
    "# Distribution of predicted total amounts\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(predictions_df['total_amount'], bins=10, kde=True)\n",
    "plt.title('Distribution of Total Amounts')\n",
    "plt.xlabel('Total Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "average_predictions_by_country = predictions_df.groupby('country_code')['y_pred'].mean().sort_values()\n",
    "average_predictions_by_country.plot(kind='bar')\n",
    "plt.title('Average Predictions by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Average Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='country_code', y='total_revenue', data=country_revenue.head(5))\n",
    "plt.title('Top 5 Countries by Total Revenue')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['transaction_date'] = pd.to_datetime(predictions_df['transaction_date'])\n",
    "plt.figure(figsize=(12, 6))\n",
    "predictions_df.groupby('transaction_date')['y_pred'].mean().plot()\n",
    "plt.title('Predictions Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = predictions_df[['total_amount', 'y_pred']].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to slides --no-input prediction.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
